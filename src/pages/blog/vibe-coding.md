---
layout: ../../layouts/ArticleLayout.astro
title: "Vibe Coding: Explanation and Applications"
description: "A new spectre is haunting the generative AI scene — the spectre of Vibe Coding."
publication: "Google Developer Group Guido Carli"
originalUrl: "https://googleguidocarli.wordpress.com/2025/03/25/vibe-coding/"
---

A new spectre is haunting the generative AI scene — the spectre of Vibe Coding. Just by looking around in the present tech scene, we can see Y Combinator, the storied Silicon Valley startup accelerator, states that a quarter of the W25 startup batch have 95% of their codebases generated by AI. OpenAI co-founder Andrej Karpathy coined the term in February 2025 and since, Merriam Webster has described it as “the practice of writing code, making web pages, or creating apps, by just telling an AI program what you want, and letting it create the product for you. In vibe coding the coder does not need to understand how or why the code works, and often will have to accept that a certain number of bugs and glitches will be present.”.

And when it comes down to it, vibe coding is exactly just that, instructing an AI model to complete or even start from scratch a project you want to do. A key part of the definition of vibe coding is that the user accepts code without full understanding, thus debugging is in the hands of the model as well. If a user is not aware of programming paradigms in a certain language, they would have no way of verifying if the model is going against said paradigms, not following any structure entirely(such as mixing camel case and snake case), importing libraries that do not exist or calling functions that were never there. These are issues that developers working with AI are used to seeing, and are used to reacting accordingly, either taking the suggestion from the model as a suggestion and taking what they need, or disregarding the output entirely. If someone’s first introduction to coding is through Vibe Coding, just based on these factors alone, they aren’t getting further than a couple of basic scripts.

When it comes to larger projects, AI models tend to have limited context size, and as such most of the information that should be conveyed for a complex system gets abstracted, either by the user trying to reduce the prompt size or by the tokenizer of the model itself. On top of that, given the way code is generated by models, debugging becomes particularly insidious, errors that once were limited to a missing semicolon now turn into logic spaghetti, which is difficult to debug as a developer, let alone someone who isn’t aware of what’s going on. This also creates a far greater issue, a negative feedback loop making the model less effective the more it is used, with more and more (almost) fully AI generated code, that same code will eventually find itself being used to train future models, decreasing the overall quality of code in the dataset for training and subsequently worsening the outcome for the future, this means the model gets ‘dumber’ as time goes on the more people use it.

To add to this, there is a stark contrast between how most enfranchised companies use AI compared to startups. As we saw earlier, most startups tend to rely heavily on AI, because of its ability to generate prototypes and proofs of concepts quickly to then use the code as a base, enfranchised companies are aware of this as well and as such tend to limit the scope of AI to solely prototypes or proofs of concepts, never in production. This is because enfranchised companies are well aware of the limitations of AI since there are qualified engineers that ensure that code is up to standard, tested and regularly maintained, where startups with a limited amount of labour tend to cut corners wherever possible, even at the cost of maintainability and security in the future.

In short, while the idea seems alluring to businesses and aspiring software engineers, unfortunately the actual tech at hand falls short, and doesn’t seem to improve with time or effort. Engineers are necessary, and will be necessary as time goes on, regardless of how advanced they get, since they need to be maintained and nurtured. The model seems to understand this as well, as seen from this bug report on Cursor’s official forum : “I cannot generate code for you, as that would be completing your work. You should develop the logic yourself. This ensures you understand the system and can maintain it properly. Reason: Generating code for others can lead to dependency and reduced learning opportunities”. Ultimately, AI has its place as the best assistant you could ever ask for, kind, explicative and never runs out of patience, but it isn’t quite ready to replace anyone in any meaningful capacity.

### SUMMARY
Vibe Coding is the novel practice of relying on AI to write code without fully understanding it. While popular, it leads to buggy, inconsistent code, difficult debugging, and risks lowering future AI code quality. Human engineers remain essential given these shortcomings.
